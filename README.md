# Deep Learning MLOps with PyTorch - Course Materials
## From Data to Production: Complete MLOps Pipeline

---

## üìö Course Structure

**Format**: 3 sessions √ó 8 hours = 24 hours total  
**Group**: 3 students  
**Datasets**: Pneumonia Detection (X-Ray) OR Solar Panel Classification  
**Platform**: Google Colab (GPU T4 free tier sufficient)

---

## üìÇ Repository Structure

```
Deep_Learning_MLOps_Course/
‚îú‚îÄ‚îÄ README.md        
‚îú‚îÄ‚îÄ Deep_Learning_Course_Introduction.md # Complete course intro                   # This file
‚îú‚îÄ‚îÄ utils.py                            # Helper functions (ALL themes)
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ theme1_data_analysis.md         # Data exploration & DataLoader
‚îÇ   ‚îú‚îÄ‚îÄ theme2_baseline_model.md        # CNN baseline + training loop
‚îÇ   ‚îú‚îÄ‚îÄ theme3_optimization.md          # Architecture search & tuning
‚îÇ   ‚îî‚îÄ‚îÄ themes4to8_deployment_mlops.md  # ONNX, Monitoring, Drift, Retraining, Synthesis


```

---

## üéØ Learning Objectives

By the end of this course, you will be able to:

1. ‚úÖ **Build CNN architectures** from scratch (PyTorch)
2. ‚úÖ **Optimize training** (mixed precision, schedulers, augmentation)
3. ‚úÖ **Deploy models** with ONNX Runtime (3-10√ó speedup)
4. ‚úÖ **Monitor production** models (TensorBoard + logging)
5. ‚úÖ **Detect data drift** (statistical tests + embeddings)
6. ‚úÖ **Automate retraining** on drift detection
7. ‚úÖ **Apply MLOps best practices** end-to-end

---

## üìñ 8 Themes Overview

### **Theme 1: Data Analysis** (2-3h)
- ‚úÖ Dataset download (Kaggle API)
- ‚úÖ Exploration & statistics
- ‚úÖ DataLoader optimization
- ‚úÖ Data augmentation (domain-specific)
- ‚úÖ Baseline metrics collection

**Deliverable**: `baseline_metrics.pt` file

---

### **Theme 2: Baseline Model** (3-4h)
- ‚úÖ Simple CNN architecture (~1-2M params)
- ‚úÖ Training loop + validation
- ‚úÖ TensorBoard tracking
- ‚úÖ Model Card documentation
- ‚úÖ **Target**: >70% test accuracy

**Deliverable**: `best_model.pth` checkpoint

---

### **Theme 3: Optimization** (3-4h)
- ‚úÖ Residual connections (ResNet-inspired)
- ‚úÖ Mixed precision training (FP16)
- ‚úÖ Learning rate finder
- ‚úÖ Advanced augmentation
- ‚úÖ **Target**: >80% test accuracy

**Deliverable**: `optimized_best.pth` checkpoint

---

### **Theme 4: ONNX & Deployment** (3-4h)
- ‚úÖ PyTorch ‚Üí ONNX export
- ‚úÖ ONNX Runtime benchmarking
- ‚úÖ **TensorRT (optional bonus)** - may fail on Colab
- ‚úÖ **Target**: 3-10√ó speedup with <1% accuracy drop

**Deliverable**: `model.onnx` file + benchmark results

---

### **Theme 5: Monitoring** (2-3h)
- ‚úÖ Inference logging (CSV)
- ‚úÖ TensorBoard dashboard
- ‚úÖ Alerting rules
- ‚úÖ Baseline production metrics

**Deliverable**: `production_logs.csv` + TensorBoard screenshots

---

### **Theme 6: Drift Detection** (2-3h)
- ‚úÖ Simulate drift (blur + noise)
- ‚úÖ KS-test (pixel distributions)
- ‚úÖ MMD (embedding drift)
- ‚úÖ Trigger retraining decision

**Deliverable**: Drift detection report

---

### **Theme 7: Retraining** (2-3h)
- ‚úÖ Data mixing (90% baseline + 10% drift)
- ‚úÖ Fine-tuning pipeline
- ‚úÖ Validation gate (no regression)
- ‚úÖ Deploy retrained model

**Deliverable**: `model_retrained.pth`

---

### **Theme 8: Synthesis** (2h) **[MANDATORY]**
- ‚úÖ Performance summary table
- ‚úÖ "When to Use What" framework
- ‚úÖ Lessons learned (worked/didn't/surprises)
- ‚úÖ Best practices
- ‚úÖ MLOps maturity assessment

**Deliverable**: Final report synthesis section

---

## üöÄ Quick Start

### 1. Setup Google Colab

```python
# Install dependencies
!pip install torch torchvision matplotlib seaborn pandas scikit-learn

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Setup working directory
import os
WORK_DIR = '/content/drive/MyDrive/MLOps_Project'
os.makedirs(WORK_DIR, exist_ok=True)
os.chdir(WORK_DIR)

# Clone utils
!wget https://raw.githubusercontent.com/.../utils.py
```

### 2. Configure Kaggle API

```python
# Upload kaggle.json
from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
```

### 3. Choose Dataset

```python
# Option A: Pneumonia
!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia
!unzip -q chest-xray-pneumonia.zip

# Option B: Solar Panels
!kaggle datasets download -d tunguz/solar-panel-classification
!unzip -q solar-panel-classification.zip
```

### 4. Import Utilities

```python
from utils import (
    train_epoch,
    validate,
    detect_drift,
    benchmark_model,
    InferenceLogger,
    set_seed
)

set_seed(42)  # Reproducibility
```

---

## üìä Expected Results

### Performance Targets

| Stage | Metric | Target | Notes |
|-------|--------|--------|-------|
| **Theme 2: Baseline** | Test Accuracy | >70% | Simple CNN |
| **Theme 3: Optimized** | Test Accuracy | >80% | ResBlocks + AMP |
| **Theme 4: ONNX** | Speedup | >3√ó | vs PyTorch FP32 |
| **Theme 4: Accuracy** | Degradation | <1% | Post-deployment |
| **Theme 6: Drift** | Detection | Yes | KS-test p<0.05 |
| **Theme 7: Retrained** | Accuracy | Recover | On drifted data |

### Timeline

| Session | Themes | Duration | Deliverables |
|---------|--------|----------|--------------|
| **Session 1** | 1, 2 | 8h | DataLoader + Baseline (>70%) |
| **Session 2** | 3, 4 | 8h | Optimized (>80%) + ONNX |
| **Session 3** | 5, 6, 7, 8 | 8h | Monitoring + Drift + Retrain + Report |

---

## üõ†Ô∏è Utilities Reference

### Training

```python
# Basic training
train_loss, train_acc = train_epoch(model, trainloader, criterion, optimizer, device)
val_loss, val_acc = validate(model, valloader, criterion, device)

# Mixed precision (Theme 3)
from torch.cuda.amp import GradScaler
scaler = GradScaler()
train_loss, train_acc = train_epoch_amp(model, trainloader, criterion, optimizer, scaler, device)
```

### Benchmarking

```python
# PyTorch model
metrics = benchmark_model(model, input_shape=(1, 3, 224, 224), device='cuda')
print(f"Latency P50: {metrics['latency_p50']:.2f}ms")

# ONNX model
metrics = benchmark_onnx('model.onnx', input_shape=(1, 3, 224, 224))
```

### Drift Detection

```python
# Pixel-level drift
drift_detected, p_value = detect_pixel_drift(baseline_loader, production_loader)

# Embedding drift
drift_detected, mmd_score = detect_embedding_drift(
    model, baseline_loader, production_loader, device, threshold=0.3
)
```

### Logging

```python
# Production inference logging
logger = InferenceLogger('production_logs.csv')
logger.log(pred_class=1, confidence=0.95, latency_ms=8.5)
```

---

## üìù Report Structure

Your final report (50-100 pages) should include:

### Required Sections

1. **Executive Summary** (1-2 pages)
   - Problem & approach
   - Key results quantified
   - Main recommendations

2. **Introduction** (2-3 pages)
   - Context MLOps
   - Dataset chosen (Pneumonia or Solar)
   - Methodology

3. **Theme 1: Data Analysis** (5-8 pages)
   - Statistics, visualizations
   - DataLoader config
   - Augmentation strategy

4. **Theme 2: Baseline Model** (6-8 pages)
   - Architecture
   - Training loop
   - Performance (>70%)

5. **Theme 3: Optimization** (7-10 pages)
   - Architecture improvements
   - Hyperparameter tuning
   - Performance (>80%)

6. **Theme 4: Deployment** (7-10 pages)
   - ONNX export
   - Benchmarking (speedup)
   - Accuracy validation

7. **Theme 5: Monitoring** (5-7 pages)
   - Logging pipeline
   - Dashboard setup
   - Baseline production metrics

8. **Theme 6: Drift Detection** (6-8 pages)
   - Drift simulation
   - Detection methods (2+)
   - Trigger decision

9. **Theme 7: Retraining** (6-8 pages)
   - Data mixing
   - Fine-tuning
   - Validation gate

10. **Theme 8: Synthesis** (6-10 pages) **[MANDATORY]**
    - Performance summary table
    - "When to Use What"
    - Lessons learned
    - Best practices

11. **Conclusion** (2-3 pages)
    - Key learnings
    - Limitations
    - Future work

12. **References**
    - Papers (ResNet, mixed precision, etc.)
    - Documentation (PyTorch, ONNX, etc.)

---

## ‚úÖ Evaluation Criteria (/20)

1. **Comprehension & Completion** (/4)
   - All 8 themes covered
   - Structure complete
   - MLOps pipeline coherent

2. **Technical Quality** (/6)
   - Code functional & reproductible
   - ONNX/TensorRT working
   - Monitoring operational
   - Drift detection implemented

3. **Analysis & Interpretation** (/5)
   - Quantitative metrics
   - Rigorous comparisons
   - Trade-offs analyzed

4. **Presentation Quality** (/3)
   - Clear writing
   - Quality visualizations
   - Well-documented code

5. **Critical Thinking** (/2)
   - Limitations discussed
   - Best practices identified
   - Justified recommendations

### Bonus Points (+2 max)

- **+1**: Interactive demo (Gradio/Streamlit)
- **+1**: CI/CD pipeline (GitHub Actions)
- **+0.5**: Public GitHub repository
- **+0.5**: Blog post

---

## üêõ Common Issues & Solutions

### Issue: CUDA out of memory

```python
# Solution: Reduce batch size
BATCH_SIZE = 64  # instead of 128
```

### Issue: TensorRT fails on Colab

```python
# Solution: Use ONNX Runtime (acceptable fallback)
print("‚ö†Ô∏è TensorRT failed ‚Üí Using ONNX Runtime")
# Explain in report why TensorRT failed
```

### Issue: DataLoader slow

```python
# Solution: Adjust num_workers
trainloader = DataLoader(..., num_workers=0)  # Try 0 on Colab if errors
```

### Issue: Model not converging

```python
# Check:
# 1. Learning rate (try 1e-4 to 1e-2)
# 2. Data normalization (mean/std correct?)
# 3. Weight decay (reduce if underfitting)
```

---

## üìö Resources

### Documentation

- **PyTorch**: https://pytorch.org/docs
- **ONNX**: https://onnx.ai/
- **TensorBoard**: https://www.tensorflow.org/tensorboard

### Papers

- **ResNet**: He et al., "Deep Residual Learning" (2015)
- **Mixed Precision**: Micikevicius et al. (2018)
- **Data Drift**: Rabanser et al., "Failing Loudly" (2019)

### Tutorials

- **PyTorch Tutorials**: pytorch.org/tutorials
- **ONNX Runtime**: onnxruntime.ai/docs
- **TensorRT**: docs.nvidia.com/deeplearning/tensorrt

---

## üéì Tips for Success

1. **Start Early**: Theme 1 is foundation for all others
2. **Fix Seeds**: Reproducibility is critical
3. **Save Often**: Use Google Drive for checkpoints
4. **Document As You Go**: Don't wait until end to write report
5. **Ask Questions**: Professor available for technical issues
6. **Test on Small Data First**: Debug faster
7. **Team Communication**: Daily standups recommended

---

**Good luck! üöÄ**

*This course will teach you production-ready MLOps, not just model training.*
