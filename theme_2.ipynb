{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fbc48f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset, ConcatDataset\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d228d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN, STD = [0.4823]*3, [0.2216]*3\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2201edda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Colab cache for faster access to the 'chest-xray-pneumonia' dataset.\n",
      "Path to dataset files: /kaggle/input/chest-xray-pneumonia\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"paultimothymooney/chest-xray-pneumonia\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98b7d772",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tf = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=MEAN, std=STD)\n",
    "])\n",
    "\n",
    "val_test_tf = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=MEAN, std=STD)\n",
    "])\n",
    "\n",
    "base_path = os.path.join(path, \"chest_xray\")\n",
    "full_train = datasets.ImageFolder(os.path.join(base_path, \"train\"), transform=train_tf)\n",
    "train_clean = datasets.ImageFolder(os.path.join(base_path, \"train\"), transform=val_test_tf)\n",
    "\n",
    "indices = torch.randperm(len(full_train), generator=torch.Generator().manual_seed(42))\n",
    "train_idx, val_idx = indices[:int(0.9*len(full_train))], indices[int(0.9*len(full_train)):]\n",
    "\n",
    "train_loader = DataLoader(Subset(full_train, train_idx), batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(ConcatDataset([datasets.ImageFolder(os.path.join(base_path, \"val\"), transform=val_test_tf), \n",
    "                                       Subset(train_clean, val_idx)]), batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a64a761",
   "metadata": {},
   "source": [
    "# Architecture baseline implémenté"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2358c2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        # Bloc 1 : 224x224 -> 112x112\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        \n",
    "        # Bloc 2 : 112x112 -> 56x56\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        # Bloc 3 : 56x56 -> 28x28\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        # Bloc 4 (Ajouté pour le budget paramètres) : 28x28 -> 14x14\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # MLP Final : Entrée 64 * 14 * 14 = 12 544\n",
    "        self.fc1 = nn.Linear(64 * 14 * 14, 128) # Réduit à 128 pour l'efficacité\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.pool(F.relu(self.bn4(self.conv4(x)))) # 4ème réduction\n",
    "        \n",
    "        x = x.view(x.size(0), -1) # Flatten propre\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4065439",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCNN().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "weights = torch.tensor([2.8, 1.0]).to(device) \n",
    "criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "writer = SummaryWriter('runs/pneumonia_baseline_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ead3330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de paramètres : 1,666,882\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Nombre de paramètres : {total_params:,}\")\n",
    "# On devrait être autour de 1.2M - 1.5M selon les tailles des FC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef891112",
   "metadata": {},
   "source": [
    "# Trainning loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84b3b369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader : <class 'torch.utils.data.dataloader.DataLoader'> - OK\n",
      "Val loader : <class 'torch.utils.data.dataloader.DataLoader'> - OK\n",
      "Batch testé : torch.Size([64, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# Test rapide : Est-ce que les loaders existent ?\n",
    "try:\n",
    "    print(f\"Train loader : {type(train_loader)} - OK\")\n",
    "    print(f\"Val loader : {type(val_loader)} - OK\")\n",
    "    # On vérifie si on peut tirer un batch\n",
    "    images, labels = next(iter(train_loader))\n",
    "    print(f\"Batch testé : {images.shape}\")\n",
    "except NameError as e:\n",
    "    print(f\"❌ Erreur : La variable n'existe pas. {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Autre erreur : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20a167d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Époque 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 74/74 [06:43<00:00,  5.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4882 | Train Acc: 86.96%\n",
      "Val Loss: 0.1019 | Val Acc: 96.28%\n",
      "⭐ Nouveau meilleur modèle sauvegardé ! (Acc: 96.28%)\n",
      "\n",
      "Époque 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 74/74 [06:44<00:00,  5.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1560 | Train Acc: 93.63%\n",
      "Val Loss: 0.1478 | Val Acc: 96.84%\n",
      "⭐ Nouveau meilleur modèle sauvegardé ! (Acc: 96.84%)\n",
      "\n",
      "Époque 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 74/74 [06:44<00:00,  5.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1278 | Train Acc: 95.31%\n",
      "Val Loss: 0.0817 | Val Acc: 97.21%\n",
      "⭐ Nouveau meilleur modèle sauvegardé ! (Acc: 97.21%)\n",
      "\n",
      "Époque 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 74/74 [06:44<00:00,  5.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1090 | Train Acc: 96.04%\n",
      "Val Loss: 0.0711 | Val Acc: 97.03%\n",
      "\n",
      "Époque 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 74/74 [06:44<00:00,  5.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1164 | Train Acc: 95.78%\n",
      "Val Loss: 0.0741 | Val Acc: 97.21%\n",
      "\n",
      "Époque 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 74/74 [06:43<00:00,  5.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1043 | Train Acc: 96.17%\n",
      "Val Loss: 0.1239 | Val Acc: 96.84%\n",
      "\n",
      "Époque 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 74/74 [06:43<00:00,  5.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1065 | Train Acc: 95.78%\n",
      "Val Loss: 0.1233 | Val Acc: 92.57%\n",
      "\n",
      "Époque 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 74/74 [06:44<00:00,  5.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0992 | Train Acc: 96.38%\n",
      "Val Loss: 0.0782 | Val Acc: 97.77%\n",
      "⭐ Nouveau meilleur modèle sauvegardé ! (Acc: 97.77%)\n",
      "\n",
      "Époque 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 74/74 [06:44<00:00,  5.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0844 | Train Acc: 96.51%\n",
      "Val Loss: 0.1017 | Val Acc: 96.84%\n",
      "\n",
      "Époque 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 3/74 [00:16<06:27,  5.46s/it]"
     ]
    }
   ],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=10):\n",
    "    best_val_acc = 0.0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        \n",
    "        print(f\"\\nÉpoque {epoch+1}/{epochs}\")\n",
    "        for images, labels in tqdm(train_loader, desc=\"Training\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "            \n",
    "        epoch_train_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_train_acc = 100 * correct_train / total_train\n",
    "        \n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                running_val_loss += loss.item() * images.size(0)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_val += labels.size(0)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "        \n",
    "        epoch_val_loss = running_val_loss / len(val_loader.dataset)\n",
    "        epoch_val_acc = 100 * correct_val / total_val\n",
    "        \n",
    "        # Logging tensorboard\n",
    "        writer.add_scalar('Loss/Train', epoch_train_loss, epoch)\n",
    "        writer.add_scalar('Loss/Val', epoch_val_loss, epoch)\n",
    "        writer.add_scalar('Accuracy/Train', epoch_train_acc, epoch)\n",
    "        writer.add_scalar('Accuracy/Val', epoch_val_acc, epoch)\n",
    "        \n",
    "        print(f\"Train Loss: {epoch_train_loss:.4f} | Train Acc: {epoch_train_acc:.2f}%\")\n",
    "        print(f\"Val Loss: {epoch_val_loss:.4f} | Val Acc: {epoch_val_acc:.2f}%\")\n",
    "        \n",
    "        # Sauvegarde du meilleur modèle\n",
    "        if epoch_val_acc > best_val_acc:\n",
    "            best_val_acc = epoch_val_acc\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            print(f\"⭐ Nouveau meilleur modèle sauvegardé ! (Acc: {best_val_acc:.2f}%)\")\n",
    "\n",
    "    writer.close()\n",
    "    print(\"\\nEntraînement terminé !\")\n",
    "\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305a059a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
